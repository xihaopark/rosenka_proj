# 路線価図地址信息提取系统 - 技术分析与工程指导书

## 1. 项目概述与现状分析

### 1.1 项目背景
日本国税厅的路線価図是用于土地评价的特殊地图PDF，其中地址信息以隐式方式存在：
- **街区番号**：地图中的孤立数字（如"42"表示某町1丁目42番）
- **路線価コード**：道路上的数字+字母组合（如"330D"，330表示33万円/㎡，D表示借地权割合）
- **特殊标记**：各种囲み记号（圆形、椭圆、六角形等）表示地区分类

### 1.2 现有系统架构分析

```
项目结构：
├── 数据获取层
│   ├── rosenka_downloader.py  # PDF下载器
│   └── url_mapper.py          # URL映射
├── 处理层
│   ├── rosenka_processor.py   # OCR处理（PaddleOCR + EasyOCR）
│   └── simple_processor.py    # 简化版处理器
├── 服务层
│   ├── simple_rosenka_service.py  # FastAPI服务
│   └── rosenka_service.py        # 完整版服务
└── 展示层
    ├── rosenka_app.py         # Streamlit应用
    └── rosenka_web.py         # Web界面
```

### 1.3 技术挑战分析

1. **OCR检测难点**：
   - 地图线条与文字混杂
   - 白底黑字和黑底白字混合
   - 文字被囲み记号包围
   - 小尺寸文字检测困难

2. **系统性能问题**：
   - 多引擎并行导致效率低下
   - 缺乏有效的结果去重机制
   - 后处理规则不够完善

## 2. 技术改进方案

### 2.1 图像预处理优化

```python
class EnhancedImagePreprocessor:
    """增强的图像预处理器"""
    
    def __init__(self):
        self.header_height = 200  # 页眉高度估计
        
    def preprocess_for_ocr(self, image: np.ndarray) -> List[np.ndarray]:
        """生成多个预处理版本以提高检测率"""
        results = []
        
        # 1. 原始图像
        results.append(image)
        
        # 2. 去除页眉
        no_header = self.remove_header(image)
        results.append(no_header)
        
        # 3. 二值化处理
        binary = self.adaptive_binarize(no_header)
        results.append(binary)
        
        # 4. 反色图像（检测白底文字）
        inverted = cv2.bitwise_not(binary)
        results.append(inverted)
        
        # 5. 形态学处理去除细线
        no_lines = self.remove_thin_lines(binary)
        results.append(no_lines)
        
        # 6. 反色的去线版本
        inverted_no_lines = cv2.bitwise_not(no_lines)
        results.append(inverted_no_lines)
        
        return results
    
    def remove_header(self, image: np.ndarray) -> np.ndarray:
        """去除页眉区域"""
        h, w = image.shape[:2]
        return image[self.header_height:, :]
    
    def adaptive_binarize(self, image: np.ndarray) -> np.ndarray:
        """自适应二值化"""
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image
            
        # 使用自适应阈值
        binary = cv2.adaptiveThreshold(
            gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY, 31, 10
        )
        return binary
    
    def remove_thin_lines(self, image: np.ndarray) -> np.ndarray:
        """去除细线（保留文字）"""
        # 水平和垂直核
        h_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 1))
        v_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 25))
        
        # 检测线条
        h_lines = cv2.morphologyEx(image, cv2.MORPH_OPEN, h_kernel)
        v_lines = cv2.morphologyEx(image, cv2.MORPH_OPEN, v_kernel)
        
        # 从原图中减去线条
        result = image.copy()
        result = cv2.subtract(result, h_lines)
        result = cv2.subtract(result, v_lines)
        
        return result
```

### 2.2 OCR检测策略优化

```python
class OptimizedOCRDetector:
    """优化的OCR检测器"""
    
    def __init__(self):
        # PaddleOCR配置（主引擎）
        self.paddle_ocr = PaddleOCR(
            use_angle_cls=True,
            lang='japan',
            det_db_thresh=0.1,  # 降低阈值提高召回率
            det_db_box_thresh=0.3,
            rec_batch_num=30
        )
        
        # 路線価図专用模式匹配
        self.patterns = {
            'block_number': r'^\d{1,3}$',  # 街区番号：1-3位数字
            'route_price': r'^\d{1,4}[A-G]$',  # 路線価：数字+字母
            'complex_number': r'^\d{1,3}-\d{1,3}$'  # 复合番号
        }
    
    def detect_multi_scale(self, image: np.ndarray) -> List[Dict]:
        """多尺度检测"""
        results = []
        scales = [1.0, 1.5, 2.0]  # 多个缩放比例
        
        for scale in scales:
            # 缩放图像
            scaled = cv2.resize(
                image, None, fx=scale, fy=scale,
                interpolation=cv2.INTER_CUBIC
            )
            
            # OCR检测
            ocr_results = self.paddle_ocr.ocr(scaled, cls=True)
            
            # 调整坐标回原始尺寸
            for line in ocr_results[0] if ocr_results[0] else []:
                bbox, (text, conf) = line
                
                # 缩放边界框坐标
                bbox = [[x/scale, y/scale] for x, y in bbox]
                
                results.append({
                    'text': text,
                    'bbox': bbox,
                    'confidence': conf,
                    'scale': scale
                })
        
        return results
    
    def classify_detection(self, text: str, bbox: List) -> str:
        """分类检测结果"""
        # 根据模式匹配分类
        for pattern_name, pattern in self.patterns.items():
            if re.match(pattern, text):
                return pattern_name
        
        # 根据位置特征分类
        # TODO: 结合空间位置信息进行分类
        
        return 'unknown'
```

### 2.3 后处理和结果整合

```python
class IntelligentPostProcessor:
    """智能后处理器"""
    
    def __init__(self):
        self.merge_threshold = 30  # 像素距离阈值
        
    def merge_nearby_detections(self, detections: List[Dict]) -> List[Dict]:
        """合并邻近的检测结果"""
        merged = []
        used = set()
        
        for i, det1 in enumerate(detections):
            if i in used:
                continue
                
            # 查找可合并的检测
            group = [det1]
            bbox1 = self._bbox_to_rect(det1['bbox'])
            
            for j, det2 in enumerate(detections[i+1:], i+1):
                if j in used:
                    continue
                    
                bbox2 = self._bbox_to_rect(det2['bbox'])
                
                # 检查是否应该合并
                if self._should_merge(bbox1, bbox2, det1['text'], det2['text']):
                    group.append(det2)
                    used.add(j)
            
            # 合并组内检测
            merged_det = self._merge_group(group)
            merged.append(merged_det)
        
        return merged
    
    def _should_merge(self, bbox1, bbox2, text1, text2):
        """判断是否应该合并两个检测"""
        # 计算距离
        dist = self._bbox_distance(bbox1, bbox2)
        
        # 规则1：非常近的数字和字母应该合并（路線価）
        if dist < self.merge_threshold:
            if text1.isdigit() and text2.isalpha():
                return True
            if text1.isalpha() and text2.isdigit():
                return True
        
        # 规则2：破折号连接的数字
        if dist < self.merge_threshold * 2:
            if text1.isdigit() and text2 == '-':
                return True
            if text1 == '-' and text2.isdigit():
                return True
        
        return False
    
    def apply_spatial_rules(self, detections: List[Dict], 
                          road_lines: List) -> List[Dict]:
        """应用空间规则过滤"""
        filtered = []
        
        for det in detections:
            bbox = self._bbox_to_rect(det['bbox'])
            
            # 规则1：路線価应该在道路附近
            if det.get('type') == 'route_price':
                if not self._near_road(bbox, road_lines):
                    continue
            
            # 规则2：街区番号应该在封闭区域内
            if det.get('type') == 'block_number':
                if not self._in_closed_area(bbox, road_lines):
                    continue
            
            filtered.append(det)
        
        return filtered
```

### 2.4 系统架构优化

```python
class RosenkaOCRPipeline:
    """路線価図OCR处理管线"""
    
    def __init__(self):
        self.preprocessor = EnhancedImagePreprocessor()
        self.detector = OptimizedOCRDetector()
        self.postprocessor = IntelligentPostProcessor()
        
    def process_pdf(self, pdf_path: str) -> List[Dict]:
        """处理单个PDF文件"""
        results = []
        
        # PDF转图像
        images = self._pdf_to_images(pdf_path)
        
        for page_num, image in enumerate(images):
            # 1. 预处理生成多个版本
            preprocessed_images = self.preprocessor.preprocess_for_ocr(image)
            
            # 2. 对每个版本进行OCR
            all_detections = []
            for prep_image in preprocessed_images:
                detections = self.detector.detect_multi_scale(prep_image)
                all_detections.extend(detections)
            
            # 3. 去重和合并
            unique_detections = self._deduplicate(all_detections)
            merged_detections = self.postprocessor.merge_nearby_detections(unique_detections)
            
            # 4. 分类和过滤
            for det in merged_detections:
                det['type'] = self.detector.classify_detection(det['text'], det['bbox'])
                det['page'] = page_num
                det['pdf'] = pdf_path
            
            # 5. 应用空间规则
            road_lines = self._extract_road_lines(image)
            filtered = self.postprocessor.apply_spatial_rules(merged_detections, road_lines)
            
            results.extend(filtered)
        
        return results
```

## 3. 实施步骤

### 第一阶段：基础改进（1-2周）
1. 实现增强的图像预处理器
2. 优化OCR参数配置
3. 实现基础的结果合并逻辑

### 第二阶段：高级功能（2-3周）
1. 实现多尺度检测
2. 开发空间规则引擎
3. 构建模式分类器

### 第三阶段：系统整合（1-2周）
1. 整合新的处理管线
2. 性能优化（并行处理、缓存）
3. 测试和调优

### 第四阶段：持续改进
1. 收集错误案例
2. 模型微调
3. 规则优化

## 4. 性能优化建议

### 4.1 并行处理
```python
from concurrent.futures import ProcessPoolExecutor

def parallel_process_pdfs(pdf_list: List[str], max_workers: int = 4):
    """并行处理多个PDF"""
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        futures = {executor.submit(process_single_pdf, pdf): pdf 
                  for pdf in pdf_list}
        
        results = {}
        for future in as_completed(futures):
            pdf = futures[future]
            try:
                results[pdf] = future.result()
            except Exception as e:
                logger.error(f"处理失败 {pdf}: {e}")
    
    return results
```

### 4.2 缓存机制
```python
class ResultCache:
    """结果缓存"""
    
    def __init__(self, cache_dir: str = ".cache"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
    
    def get_cache_key(self, pdf_path: str) -> str:
        """生成缓存键"""
        file_stat = os.stat(pdf_path)
        return hashlib.md5(
            f"{pdf_path}_{file_stat.st_mtime}_{file_stat.st_size}".encode()
        ).hexdigest()
    
    def get(self, pdf_path: str) -> Optional[List[Dict]]:
        """获取缓存结果"""
        cache_key = self.get_cache_key(pdf_path)
        cache_file = self.cache_dir / f"{cache_key}.json"
        
        if cache_file.exists():
            with open(cache_file, 'r') as f:
                return json.load(f)
        return None
    
    def set(self, pdf_path: str, results: List[Dict]):
        """设置缓存"""
        cache_key = self.get_cache_key(pdf_path)
        cache_file = self.cache_dir / f"{cache_key}.json"
        
        with open(cache_file, 'w') as f:
            json.dump(results, f)
```

## 5. 测试和验证

### 5.1 单元测试示例
```python
import unittest

class TestOCRPipeline(unittest.TestCase):
    
    def setUp(self):
        self.pipeline = RosenkaOCRPipeline()
    
    def test_block_number_detection(self):
        """测试街区番号检测"""
        # 准备测试图像
        test_image = self._create_test_image_with_number("42")
        
        # 执行检测
        results = self.pipeline.detector.detect_multi_scale(test_image)
        
        # 验证结果
        self.assertTrue(any(r['text'] == "42" for r in results))
    
    def test_route_price_detection(self):
        """测试路線価检测"""
        test_image = self._create_test_image_with_text("330D")
        
        results = self.pipeline.detector.detect_multi_scale(test_image)
        
        self.assertTrue(any(r['text'] == "330D" for r in results))
```

### 5.2 性能基准测试
```python
def benchmark_performance():
    """性能基准测试"""
    import time
    
    test_pdfs = list(Path("test_data").glob("*.pdf"))
    
    # 测试处理时间
    start_time = time.time()
    results = parallel_process_pdfs(test_pdfs)
    end_time = time.time()
    
    # 统计指标
    total_detections = sum(len(r) for r in results.values())
    avg_time_per_pdf = (end_time - start_time) / len(test_pdfs)
    
    print(f"处理 {len(test_pdfs)} 个PDF")
    print(f"总检测数: {total_detections}")
    print(f"平均处理时间: {avg_time_per_pdf:.2f} 秒/PDF")
```

## 6. 部署建议

### 6.1 Docker容器化
```dockerfile
FROM python:3.9-slim

# 安装系统依赖
RUN apt-get update && apt-get install -y \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    wget \
    && rm -rf /var/lib/apt/lists/*

# 安装Python依赖
COPY requirements.txt .
RUN pip install -r requirements.txt

# 复制应用代码
COPY . /app
WORKDIR /app

# 启动服务
CMD ["python", "app_main.py"]
```

### 6.2 生产环境配置
```yaml
# docker-compose.yml
version: '3.8'

services:
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - PYTHONUNBUFFERED=1
      - MAX_WORKERS=4
    volumes:
      - ./rosenka_data:/app/rosenka_data
      - ./cache:/app/.cache
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
```

## 7. 监控和维护

### 7.1 日志和监控
```python
import structlog

logger = structlog.get_logger()

class MonitoredPipeline(RosenkaOCRPipeline):
    """带监控的处理管线"""
    
    def process_pdf(self, pdf_path: str) -> List[Dict]:
        """处理PDF并记录指标"""
        start_time = time.time()
        
        try:
            results = super().process_pdf(pdf_path)
            
            # 记录成功指标
            logger.info(
                "pdf_processed",
                pdf=pdf_path,
                duration=time.time() - start_time,
                detections=len(results),
                status="success"
            )
            
            return results
            
        except Exception as e:
            # 记录错误
            logger.error(
                "pdf_processing_failed",
                pdf=pdf_path,
                duration=time.time() - start_time,
                error=str(e),
                status="error"
            )
            raise
```

## 8. 总结

本指导书提供了路線価図地址信息提取系统的全面改进方案：

1. **技术改进**：
   - 多版本图像预处理
   - 多尺度OCR检测
   - 智能后处理和空间规则

2. **工程优化**：
   - 并行处理架构
   - 缓存机制
   - 容器化部署

3. **质量保证**：
   - 完整的测试方案
   - 性能监控
   - 持续改进流程

通过实施这些改进，预期可以：
- 将检测召回率提升至95%以上
- 将误检率控制在5%以内
- 处理速度提升3-5倍

建议按照分阶段实施计划逐步推进，确保系统稳定性和可维护性。
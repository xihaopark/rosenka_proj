#!/usr/bin/env python3
import sys
import os
import cv2
import numpy as np
import json
import sqlite3
from pathlib import Path
import logging
from datetime import datetime
from typing import List, Dict, Tuple, Optional
import hashlib

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ResultProcessor:
    """ç»“æœå¤„ç†å™¨ - å°†æ£€æµ‹ç»“æœæ ‡å‡†åŒ–å¹¶ä¿å­˜"""
    
    def __init__(self, db_path="rosenka_detection_results.db"):
        self.db_path = db_path
        self.logger = logging.getLogger(__name__)
        self.init_database()
    
    def init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # åˆ›å»ºæ£€æµ‹ç»“æœè¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS detection_results (
                id TEXT PRIMARY KEY,
                pdf_path TEXT NOT NULL,
                page_num INTEGER NOT NULL,
                text_content TEXT,
                bbox_x1 INTEGER,
                bbox_y1 INTEGER,
                bbox_x2 INTEGER,
                bbox_y2 INTEGER,
                center_x INTEGER,
                center_y INTEGER,
                confidence REAL,
                detection_type TEXT,
                ocr_method TEXT,
                circle_radius INTEGER,
                patch_info TEXT,
                created_at TEXT,
                UNIQUE(pdf_path, page_num, bbox_x1, bbox_y1, bbox_x2, bbox_y2)
            )
        ''')
        
        # åˆ›å»ºç´¢å¼•
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_text_content ON detection_results(text_content)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_pdf_path ON detection_results(pdf_path)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_detection_type ON detection_results(detection_type)')
        
        conn.commit()
        conn.close()
        
        self.logger.info(f"æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ: {self.db_path}")
    
    def process_fixed_ocr_results(self, json_file="fixed_ocr_results.json", pdf_path="", page_num=0):
        """å¤„ç†fixed_ocr_processorçš„ç»“æœ"""
        if not os.path.exists(json_file):
            self.logger.error(f"ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {json_file}")
            return []
        
        with open(json_file, 'r', encoding='utf-8') as f:
            results = json.load(f)
        
        processed_results = []
        
        for result in results:
            # ç”Ÿæˆå”¯ä¸€ID
            result_id = self.generate_result_id(pdf_path, page_num, result)
            
            # è®¡ç®—ä¸­å¿ƒç‚¹
            bbox = result['bbox']
            center_x = (bbox[0] + bbox[2]) // 2
            center_y = (bbox[1] + bbox[3]) // 2
            
            processed_result = {
                'id': result_id,
                'pdf_path': pdf_path,
                'page_num': page_num,
                'text_content': result['text'],
                'bbox': bbox,
                'center': [center_x, center_y],
                'confidence': float(result['confidence']),
                'detection_type': result['type'],
                'ocr_method': result['method'],
                'circle_radius': None,
                'patch_info': None,
                'created_at': datetime.now().isoformat()
            }
            
            processed_results.append(processed_result)
        
        return processed_results
    
    def process_circle_detection_results(self, circle_rois_dir="circle_rois", pdf_path="", page_num=0):
        """å¤„ç†åœ†å½¢æ£€æµ‹ç»“æœ"""
        if not os.path.exists(circle_rois_dir):
            self.logger.error(f"åœ†å½¢ROIç›®å½•ä¸å­˜åœ¨: {circle_rois_dir}")
            return []
        
        processed_results = []
        
        # éå†circle_roisç›®å½•
        for roi_file in sorted(os.listdir(circle_rois_dir)):
            if roi_file.endswith('_original.jpg'):
                # æå–åœ†å½¢ç¼–å·
                circle_num = roi_file.split('_')[1]
                
                # å°è¯•è¯»å–å¯¹åº”çš„å¤„ç†åå›¾åƒ
                processed_file = f"circle_{circle_num}_processed.jpg"
                processed_path = os.path.join(circle_rois_dir, processed_file)
                
                if os.path.exists(processed_path):
                    # ä½¿ç”¨EasyOCRè¯†åˆ«å¤„ç†åçš„å›¾åƒ
                    text_content = self.ocr_roi_image(processed_path)
                    
                    # ç”Ÿæˆç»“æœè®°å½•
                    result_id = f"circle_{pdf_path.replace('/', '_')}_{page_num}_{circle_num}"
                    
                    processed_result = {
                        'id': result_id,
                        'pdf_path': pdf_path,
                        'page_num': page_num,
                        'text_content': text_content,
                        'bbox': None,  # åœ†å½¢æ£€æµ‹æš‚æ—¶æ²¡æœ‰ç²¾ç¡®çš„bbox
                        'center': None,  # éœ€è¦ä»æ£€æµ‹ç»“æœä¸­è·å–
                        'confidence': 0.8,  # é»˜è®¤ç½®ä¿¡åº¦
                        'detection_type': 'circle',
                        'ocr_method': 'easyocr',
                        'circle_radius': None,  # éœ€è¦ä»æ£€æµ‹ç»“æœä¸­è·å–
                        'patch_info': {
                            'original_roi': os.path.join(circle_rois_dir, roi_file),
                            'processed_roi': processed_path
                        },
                        'created_at': datetime.now().isoformat()
                    }
                    
                    processed_results.append(processed_result)
        
        return processed_results
    
    def ocr_roi_image(self, image_path):
        """å¯¹ROIå›¾åƒè¿›è¡ŒOCRè¯†åˆ«"""
        try:
            import easyocr
            reader = easyocr.Reader(['ja', 'en'])
            
            # è¯»å–å›¾åƒ
            image = cv2.imread(image_path)
            if image is None:
                return ""
            
            # OCRè¯†åˆ«
            results = reader.readtext(image)
            
            if not results:
                return ""
            
            # é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„ç»“æœ
            best_result = max(results, key=lambda x: x[2])
            return best_result[1]
            
        except Exception as e:
            self.logger.error(f"OCRè¯†åˆ«å¤±è´¥ {image_path}: {e}")
            return ""
    
    def generate_result_id(self, pdf_path, page_num, result):
        """ç”Ÿæˆå”¯ä¸€çš„ç»“æœID"""
        # ä½¿ç”¨æ–‡ä»¶è·¯å¾„ã€é¡µç å’Œè¾¹ç•Œæ¡†ä¿¡æ¯ç”Ÿæˆå“ˆå¸Œ
        bbox = result.get('bbox', [0, 0, 0, 0])
        text = result.get('text', '')
        
        id_string = f"{pdf_path}_{page_num}_{bbox[0]}_{bbox[1]}_{bbox[2]}_{bbox[3]}_{text}"
        return hashlib.md5(id_string.encode()).hexdigest()[:16]
    
    def save_to_database(self, results):
        """ä¿å­˜ç»“æœåˆ°æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        saved_count = 0
        
        for result in results:
            try:
                # å¤„ç†patch_info
                patch_info_json = json.dumps(result.get('patch_info'), ensure_ascii=False) if result.get('patch_info') else None
                
                cursor.execute('''
                    INSERT OR REPLACE INTO detection_results 
                    (id, pdf_path, page_num, text_content, bbox_x1, bbox_y1, bbox_x2, bbox_y2, 
                     center_x, center_y, confidence, detection_type, ocr_method, circle_radius, 
                     patch_info, created_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    result['id'],
                    result['pdf_path'],
                    result['page_num'],
                    result['text_content'],
                    result['bbox'][0] if result['bbox'] else None,
                    result['bbox'][1] if result['bbox'] else None,
                    result['bbox'][2] if result['bbox'] else None,
                    result['bbox'][3] if result['bbox'] else None,
                    result['center'][0] if result['center'] else None,
                    result['center'][1] if result['center'] else None,
                    result['confidence'],
                    result['detection_type'],
                    result['ocr_method'],
                    result['circle_radius'],
                    patch_info_json,
                    result['created_at']
                ))
                
                saved_count += 1
                
            except sqlite3.Error as e:
                self.logger.error(f"ä¿å­˜ç»“æœå¤±è´¥: {e}")
                continue
        
        conn.commit()
        conn.close()
        
        self.logger.info(f"æˆåŠŸä¿å­˜ {saved_count} æ¡ç»“æœåˆ°æ•°æ®åº“")
        return saved_count
    
    def save_to_json(self, results, output_file="standardized_results.json"):
        """ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶"""
        try:
            # ç¡®ä¿æ‰€æœ‰æ•°æ®éƒ½æ˜¯JSONå¯åºåˆ—åŒ–çš„
            serializable_results = []
            
            for result in results:
                serializable_result = {}
                for key, value in result.items():
                    if isinstance(value, (np.integer, np.int64)):
                        serializable_result[key] = int(value)
                    elif isinstance(value, (np.floating, np.float64)):
                        serializable_result[key] = float(value)
                    elif isinstance(value, np.ndarray):
                        serializable_result[key] = value.tolist()
                    else:
                        serializable_result[key] = value
                
                serializable_results.append(serializable_result)
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(serializable_results, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
            return True
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜JSONå¤±è´¥: {e}")
            return False
    
    def create_summary_report(self, results):
        """åˆ›å»ºæ‘˜è¦æŠ¥å‘Š"""
        if not results:
            return {}
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_count = len(results)
        
        # æŒ‰æ£€æµ‹ç±»å‹ç»Ÿè®¡
        type_counts = {}
        for result in results:
            detection_type = result.get('detection_type', 'unknown')
            type_counts[detection_type] = type_counts.get(detection_type, 0) + 1
        
        # æŒ‰OCRæ–¹æ³•ç»Ÿè®¡
        method_counts = {}
        for result in results:
            ocr_method = result.get('ocr_method', 'unknown')
            method_counts[ocr_method] = method_counts.get(ocr_method, 0) + 1
        
        # ç½®ä¿¡åº¦ç»Ÿè®¡
        confidences = [result.get('confidence', 0) for result in results]
        avg_confidence = sum(confidences) / len(confidences) if confidences else 0
        
        # æ–‡æœ¬å†…å®¹ç»Ÿè®¡
        text_contents = [result.get('text_content', '') for result in results if result.get('text_content')]
        unique_texts = len(set(text_contents))
        
        summary = {
            'total_detections': total_count,
            'detection_types': type_counts,
            'ocr_methods': method_counts,
            'average_confidence': round(avg_confidence, 3),
            'unique_text_count': unique_texts,
            'processing_time': datetime.now().isoformat()
        }
        
        return summary
    
    def search_results(self, query_text, limit=10):
        """æœç´¢ç»“æœ"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # æ¨¡ç³Šæœç´¢
        cursor.execute('''
            SELECT * FROM detection_results 
            WHERE text_content LIKE ? 
            ORDER BY confidence DESC 
            LIMIT ?
        ''', (f'%{query_text}%', limit))
        
        results = cursor.fetchall()
        conn.close()
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        columns = ['id', 'pdf_path', 'page_num', 'text_content', 'bbox_x1', 'bbox_y1', 
                  'bbox_x2', 'bbox_y2', 'center_x', 'center_y', 'confidence', 
                  'detection_type', 'ocr_method', 'circle_radius', 'patch_info', 'created_at']
        
        formatted_results = []
        for row in results:
            result_dict = dict(zip(columns, row))
            # é‡æ„bboxå’Œcenter
            if all(result_dict[f'bbox_{axis}'] is not None for axis in ['x1', 'y1', 'x2', 'y2']):
                result_dict['bbox'] = [
                    result_dict['bbox_x1'], result_dict['bbox_y1'],
                    result_dict['bbox_x2'], result_dict['bbox_y2']
                ]
            if result_dict['center_x'] is not None and result_dict['center_y'] is not None:
                result_dict['center'] = [result_dict['center_x'], result_dict['center_y']]
            
            formatted_results.append(result_dict)
        
        return formatted_results

def main():
    """ä¸»å‡½æ•°"""
    processor = ResultProcessor()
    
    # å¤„ç†fixed_ocr_processorçš„ç»“æœ
    pdf_path = "rosenka_data/å¤§é˜ªåºœ/å¹ç”°å¸‚/è—¤ç™½å°ï¼‘/43012.pdf"
    page_num = 0
    
    print("ğŸ”„ å¤„ç†OCRè¯†åˆ«ç»“æœ...")
    ocr_results = processor.process_fixed_ocr_results("fixed_ocr_results.json", pdf_path, page_num)
    print(f"âœ… å¤„ç†äº† {len(ocr_results)} æ¡OCRç»“æœ")
    
    # å¤„ç†åœ†å½¢æ£€æµ‹ç»“æœ
    print("ğŸ”„ å¤„ç†åœ†å½¢æ£€æµ‹ç»“æœ...")
    circle_results = processor.process_circle_detection_results("circle_rois", pdf_path, page_num)
    print(f"âœ… å¤„ç†äº† {len(circle_results)} æ¡åœ†å½¢æ£€æµ‹ç»“æœ")
    
    # åˆå¹¶ç»“æœ
    all_results = ocr_results + circle_results
    print(f"ğŸ“Š æ€»è®¡ {len(all_results)} æ¡æ£€æµ‹ç»“æœ")
    
    # ä¿å­˜åˆ°æ•°æ®åº“
    print("ğŸ’¾ ä¿å­˜åˆ°æ•°æ®åº“...")
    saved_count = processor.save_to_database(all_results)
    
    # ä¿å­˜åˆ°JSON
    print("ğŸ“„ ä¿å­˜åˆ°JSON...")
    processor.save_to_json(all_results, "standardized_detection_results.json")
    
    # åˆ›å»ºæ‘˜è¦æŠ¥å‘Š
    print("ğŸ“ˆ ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š...")
    summary = processor.create_summary_report(all_results)
    
    with open("detection_summary.json", 'w', encoding='utf-8') as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“‹ å¤„ç†æ‘˜è¦:")
    print(f"æ€»æ£€æµ‹æ•°é‡: {summary['total_detections']}")
    print(f"æ£€æµ‹ç±»å‹: {summary['detection_types']}")
    print(f"OCRæ–¹æ³•: {summary['ocr_methods']}")
    print(f"å¹³å‡ç½®ä¿¡åº¦: {summary['average_confidence']}")
    print(f"å”¯ä¸€æ–‡æœ¬æ•°: {summary['unique_text_count']}")
    
    # æµ‹è¯•æœç´¢åŠŸèƒ½
    print(f"\nğŸ” æµ‹è¯•æœç´¢åŠŸèƒ½:")
    test_queries = ["è—¤ç™½", "1", "é“è·¯"]
    
    for query in test_queries:
        results = processor.search_results(query, limit=5)
        print(f"æœç´¢ '{query}': æ‰¾åˆ° {len(results)} æ¡ç»“æœ")
        for i, result in enumerate(results[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
            print(f"  {i+1}. {result['text_content']} (ç½®ä¿¡åº¦: {result['confidence']})")
    
    print(f"\nâœ… æ‰€æœ‰ç»“æœå·²æ ‡å‡†åŒ–å¹¶ä¿å­˜!")
    print(f"âœ… æ•°æ®åº“: {processor.db_path}")
    print(f"âœ… JSONæ–‡ä»¶: standardized_detection_results.json")
    print(f"âœ… æ‘˜è¦æŠ¥å‘Š: detection_summary.json")

if __name__ == "__main__":
    main() 
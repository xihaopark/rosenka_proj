#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
minimal_rosenka_app.py
æç®€ç‰ˆè·¯ç·šä¾¡å›³æŸ¥è¯¢ç³»ç»Ÿ - åŸºäºæ–‡ä»¶å¤¹ç»“æ„çš„ç²¾ç¡®æŸ¥æ‰¾
"""

import streamlit as st
import torch
from pathlib import Path
import numpy as np
from PIL import Image
import cv2
import json
from typing import List, Dict, Tuple
from dataclasses import dataclass
import logging

# é…ç½®
st.set_page_config(
    page_title="è·¯ç·šä¾¡å›³æŸ¥è¯¢",
    page_icon="ğŸ—¾",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# æç®€æ ·å¼
st.markdown("""
<style>
    .main > div {
        padding-top: 2rem;
    }
    .stTextInput > div > div > input {
        font-size: 20px;
        padding: 10px;
    }
    .search-button {
        font-size: 18px;
        padding: 10px 30px;
    }
</style>
""", unsafe_allow_html=True)

@dataclass
class TextRegion:
    """æ£€æµ‹åˆ°çš„æ–‡æœ¬åŒºåŸŸ"""
    image: np.ndarray
    bbox: Tuple[int, int, int, int]  # x1, y1, x2, y2
    confidence: float
    page_num: int
    pdf_path: str
    text: str = ""  # OCRåå¡«å……
    
class AddressParser:
    """åœ°å€è§£æå™¨ - å°†è¾“å…¥åœ°å€è§£æä¸ºæ–‡ä»¶è·¯å¾„"""
    
    def __init__(self, data_dir: Path):
        self.data_dir = data_dir
        self.structure = self._build_structure()
    
    def _build_structure(self) -> Dict:
        """æ„å»ºæ–‡ä»¶å¤¹ç»“æ„ç´¢å¼•"""
        structure = {}
        
        for prefecture_path in self.data_dir.iterdir():
            if not prefecture_path.is_dir():
                continue
                
            prefecture = prefecture_path.name
            structure[prefecture] = {}
            
            for city_path in prefecture_path.iterdir():
                if not city_path.is_dir():
                    continue
                    
                city = city_path.name
                structure[prefecture][city] = {}
                
                for district_path in city_path.iterdir():
                    if not district_path.is_dir():
                        continue
                        
                    district = district_path.name
                    pdf_files = list(district_path.glob("*.pdf"))
                    if pdf_files:
                        structure[prefecture][city][district] = pdf_files
        
        return structure
    
    def parse_address(self, address: str) -> List[Path]:
        """è§£æåœ°å€å¹¶è¿”å›å¯¹åº”çš„PDFæ–‡ä»¶è·¯å¾„åˆ—è¡¨"""
        # æ™ºèƒ½è§£æåœ°å€ç»„æˆéƒ¨åˆ†
        parts = self._extract_address_parts(address)
        
        # æ ¹æ®è§£æç»“æœæŸ¥æ‰¾PDFæ–‡ä»¶
        pdf_files = []
        
        if parts['prefecture'] and parts['city'] and parts['district']:
            # ç²¾ç¡®åŒ¹é…
            files = self.structure.get(parts['prefecture'], {}).get(parts['city'], {}).get(parts['district'], [])
            pdf_files.extend(files)
        elif parts['prefecture'] and parts['city']:
            # åŒ¹é…å¸‚çº§æ‰€æœ‰åœ°åŒº
            city_data = self.structure.get(parts['prefecture'], {}).get(parts['city'], {})
            for district_files in city_data.values():
                pdf_files.extend(district_files)
        elif parts['prefecture']:
            # åŒ¹é…å¿çº§æ‰€æœ‰åœ°åŒº
            prefecture_data = self.structure.get(parts['prefecture'], {})
            for city_data in prefecture_data.values():
                for district_files in city_data.values():
                    pdf_files.extend(district_files)
        
        return pdf_files
    
    def _extract_address_parts(self, address: str) -> Dict[str, str]:
        """æ™ºèƒ½æå–åœ°å€ç»„æˆéƒ¨åˆ†"""
        # è¿™é‡Œå¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„NLPæ–¹æ³•
        # ç®€å•å®ç°ï¼šåŸºäºå…³é”®è¯åŒ¹é…
        
        parts = {
            'prefecture': '',
            'city': '',
            'district': ''
        }
        
        # éƒ½é“åºœçœŒå…³é”®è¯
        prefectures = ['åŒ—æµ·é“', 'æ±äº¬éƒ½', 'å¤§é˜ªåºœ', 'äº¬éƒ½åºœ'] + [f'{p}çœŒ' for p in [
            'é’æ£®', 'å²©æ‰‹', 'å®®åŸ', 'ç§‹ç”°', 'å±±å½¢', 'ç¦å³¶',
            'èŒ¨åŸ', 'æ ƒæœ¨', 'ç¾¤é¦¬', 'åŸ¼ç‰', 'åƒè‘‰', 'ç¥å¥ˆå·',
            # ... å…¶ä»–å¿
        ]]
        
        for pref in prefectures:
            if pref in address:
                parts['prefecture'] = pref
                address = address.replace(pref, '')
                break
        
        # æå–å¸‚åŒºç”ºæ‘
        if 'å¸‚' in address:
            idx = address.find('å¸‚')
            parts['city'] = address[:idx+1]
            address = address[idx+1:]
        
        # å‰©ä½™éƒ¨åˆ†ä½œä¸ºåœ°åŒº
        if address:
            parts['district'] = address.strip()
        
        return parts

class TextDetectionModel:
    """æ–‡æœ¬æ£€æµ‹æ¨¡å‹ - ä½¿ç”¨é¢„è®­ç»ƒçš„CVæ¨¡å‹"""
    
    def __init__(self, device='cuda'):
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        self.model = self._load_model()
        
    def _load_model(self):
        """åŠ è½½é¢„è®­ç»ƒçš„æ–‡æœ¬æ£€æµ‹æ¨¡å‹"""
        # ä½¿ç”¨DBNetæˆ–CRAFTç­‰æ¨¡å‹
        # è¿™é‡Œä»¥DBNetä¸ºä¾‹
        try:
            # å°è¯•åŠ è½½æœ¬åœ°æ¨¡å‹
            model = torch.hub.load('pytorch/vision', 'dbnet_r50_fpn', pretrained=True)
            model = model.to(self.device)
            model.eval()
            return model
        except:
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨æ›´ç®€å•çš„è¾¹ç¼˜æ£€æµ‹
            st.warning("ä½¿ç”¨å¤‡ç”¨æ–‡æœ¬æ£€æµ‹æ–¹æ¡ˆ")
            return None
    
    def detect_text_regions(self, image: np.ndarray) -> List[TextRegion]:
        """æ£€æµ‹å›¾åƒä¸­çš„æ–‡æœ¬åŒºåŸŸ"""
        if self.model is not None:
            return self._detect_with_model(image)
        else:
            return self._detect_with_traditional(image)
    
    def _detect_with_model(self, image: np.ndarray) -> List[TextRegion]:
        """ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹æ£€æµ‹"""
        # é¢„å¤„ç†
        img_tensor = self._preprocess_image(image)
        
        # æ¨ç†
        with torch.no_grad():
            predictions = self.model(img_tensor)
        
        # åå¤„ç†
        regions = self._postprocess_predictions(predictions, image)
        return regions
    
    def _detect_with_traditional(self, image: np.ndarray) -> List[TextRegion]:
        """ä½¿ç”¨ä¼ ç»ŸCVæ–¹æ³•æ£€æµ‹æ–‡æœ¬åŒºåŸŸ"""
        regions = []
        
        # è½¬æ¢ä¸ºç°åº¦å›¾
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        
        # è¾¹ç¼˜æ£€æµ‹
        edges = cv2.Canny(gray, 50, 150)
        
        # å½¢æ€å­¦æ“ä½œ
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (10, 2))
        dilated = cv2.dilate(edges, kernel, iterations=2)
        
        # æŸ¥æ‰¾è½®å»“
        contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # è¿‡æ»¤å’Œæå–æ–‡æœ¬åŒºåŸŸ
        for contour in contours:
            x, y, w, h = cv2.boundingRect(contour)
            
            # è¿‡æ»¤æ¡ä»¶
            if w > 30 and h > 10 and w/h < 20:
                bbox = (x, y, x+w, y+h)
                region_img = image[y:y+h, x:x+w]
                
                regions.append(TextRegion(
                    image=region_img,
                    bbox=bbox,
                    confidence=0.8,
                    page_num=0,
                    pdf_path=""
                ))
        
        return regions
    
    def _preprocess_image(self, image: np.ndarray) -> torch.Tensor:
        """å›¾åƒé¢„å¤„ç†"""
        # æ ‡å‡†åŒ–ç­‰å¤„ç†
        img = Image.fromarray(image)
        # ... é¢„å¤„ç†æ­¥éª¤
        return torch.tensor(image).unsqueeze(0).to(self.device)

class MinimalRosenkaApp:
    """æç®€è·¯ç·šä¾¡å›³æŸ¥è¯¢åº”ç”¨"""
    
    def __init__(self):
        self.data_dir = Path("rosenka_data")
        self.parser = AddressParser(self.data_dir)
        self.detector = TextDetectionModel()
        
    def run(self):
        """è¿è¡Œåº”ç”¨"""
        # æ ‡é¢˜
        st.markdown("<h1 style='text-align: center;'>ğŸ—¾ è·¯ç·šä¾¡å›³æŸ¥è¯¢</h1>", unsafe_allow_html=True)
        
        # æœç´¢æ¡†
        col1, col2, col3 = st.columns([1, 3, 1])
        with col2:
            address = st.text_input(
                "",
                placeholder="è¾“å…¥åœ°å€ï¼ˆä¾‹ï¼šå¤§é˜ªåºœå¤§é˜ªå¸‚åŒ—åŒºï¼‰",
                key="address_input"
            )
            
            search_button = st.button("ğŸ” æŸ¥è¯¢", use_container_width=True)
        
        # æ‰§è¡Œæœç´¢
        if search_button and address:
            self._perform_search(address)
    
    def _perform_search(self, address: str):
        """æ‰§è¡Œæœç´¢"""
        with st.spinner("æŸ¥æ‰¾ä¸­..."):
            # 1. è§£æåœ°å€å¹¶æ‰¾åˆ°PDFæ–‡ä»¶
            pdf_files = self.parser.parse_address(address)
            
            if not pdf_files:
                st.error("æœªæ‰¾åˆ°ç›¸å…³æ–‡ä»¶")
                return
            
            st.success(f"æ‰¾åˆ° {len(pdf_files)} ä¸ªç›¸å…³æ–‡ä»¶")
            
            # 2. å¤„ç†æ¯ä¸ªPDFæ–‡ä»¶
            all_regions = []
            
            for pdf_path in pdf_files[:5]:  # é™åˆ¶å¤„ç†æ•°é‡
                regions = self._process_pdf(pdf_path)
                all_regions.extend(regions)
            
            # 3. æ˜¾ç¤ºç»“æœ
            self._display_results(all_regions)
    
    def _process_pdf(self, pdf_path: Path) -> List[TextRegion]:
        """å¤„ç†å•ä¸ªPDFæ–‡ä»¶"""
        import fitz
        
        regions = []
        doc = fitz.open(str(pdf_path))
        
        # åªå¤„ç†å‰å‡ é¡µ
        for page_num in range(min(len(doc), 3)):
            page = doc[page_num]
            pix = page.get_pixmap(dpi=300)
            img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
            img_array = np.array(img)
            
            # æ£€æµ‹æ–‡æœ¬åŒºåŸŸ
            page_regions = self.detector.detect_text_regions(img_array)
            
            # è®¾ç½®PDFè·¯å¾„å’Œé¡µç 
            for region in page_regions:
                region.pdf_path = str(pdf_path)
                region.page_num = page_num
            
            regions.extend(page_regions)
        
        doc.close()
        return regions
    
    def _display_results(self, regions: List[TextRegion]):
        """æ˜¾ç¤ºæ£€æµ‹ç»“æœ"""
        st.subheader(f"æ£€æµ‹åˆ° {len(regions)} ä¸ªæ–‡æœ¬åŒºåŸŸ")
        
        # æŒ‰é¡µåˆ†ç»„æ˜¾ç¤º
        pages = {}
        for region in regions:
            key = f"{Path(region.pdf_path).name} - ç¬¬{region.page_num + 1}é¡µ"
            if key not in pages:
                pages[key] = []
            pages[key].append(region)
        
        for page_key, page_regions in pages.items():
            with st.expander(page_key):
                # æ˜¾ç¤ºæ£€æµ‹åˆ°çš„åŒºåŸŸ
                cols = st.columns(3)
                for i, region in enumerate(page_regions[:9]):  # æœ€å¤šæ˜¾ç¤º9ä¸ª
                    with cols[i % 3]:
                        # æ˜¾ç¤ºåŒºåŸŸå›¾åƒ
                        st.image(region.image, use_column_width=True)
                        st.caption(f"åŒºåŸŸ {i+1} (ç½®ä¿¡åº¦: {region.confidence:.2f})")

def main():
    """ä¸»å‡½æ•°"""
    app = MinimalRosenkaApp()
    app.run()

if __name__ == "__main__":
    main()